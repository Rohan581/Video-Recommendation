{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohan581/Video-Recommendation/blob/main/Video_Recommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing pytube"
      ],
      "metadata": {
        "id": "0sQvuwYNs3d2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTs0SIYZ0_Nl"
      },
      "outputs": [],
      "source": [
        "!pip install pytube"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing required libraries"
      ],
      "metadata": {
        "id": "ZrhjjL8ctLYL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "E3qJ2gz9DuLI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import re\n",
        "from pytube import YouTube\n",
        "import ast"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up YOLO"
      ],
      "metadata": {
        "id": "dZWUYgz3tYdn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hwj2poLL1027"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PATH'] += ':/usr/local/cuda/bin'\n",
        "!rm -fr darknet\n",
        "!git clone https://github.com/AlexeyAB/darknet\n",
        "%cd /content/darknet\n",
        "!sed -i 's/GPU=0/GPU=1/g' Makefile\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/g' Makefile\n",
        "!make\n",
        "!wget https://pjreddie.com/media/files/yolov3.weights\n",
        "!chmod a+x ./darknet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting up requirements for YOLO**"
      ],
      "metadata": {
        "id": "iLEAzSwyuEVb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyfmzE-v8AjP"
      },
      "outputs": [],
      "source": [
        "!apt install ffmpeg libopencv-dev libgtk-3-dev python-numpy python3-numpy libdc1394-22 libdc1394-22-dev libjpeg-dev libtiff5-dev libavcodec-dev libavformat-dev libswscale-dev libxine2-dev libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libv4l-dev libtbb-dev qtbase5-dev libfaac-dev libmp3lame-dev libopencore-amrnb-dev libopencore-amrwb-dev libtheora-dev libvorbis-dev libxvidcore-dev x264 v4l-utils unzip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Initialising YOLO**"
      ],
      "metadata": {
        "id": "SS4rmImluWct"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kNHBq8IM_4go"
      },
      "outputs": [],
      "source": [
        "net = cv2.dnn.readNet(\"yolov3.weights\", \"/content/darknet/cfg/yolov3.cfg\")\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
        "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
        "classes = []\n",
        "with open(\"/content/darknet/data/coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function below is used to extract frames from a Youtube video and returns a list of unique objects present in the video."
      ],
      "metadata": {
        "id": "oRCxXRETxtQq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0HYlQSXAR3ch"
      },
      "outputs": [],
      "source": [
        "def extract_frames_with_yolo(url):\n",
        "\n",
        "    # Download YouTube video and extract frames\n",
        "    yt = YouTube(url)\n",
        "    stream = yt.streams.filter(progressive=True, file_extension=\"mp4\").order_by(\"resolution\").desc().first()\n",
        "    stream.download(filename=\"video.mp4\")\n",
        "    cap = cv2.VideoCapture(\"video.mp4\")\n",
        "    frame_count = 0\n",
        "    frames = []\n",
        "    class_ids_list = [] # List of class_ids for each frame\n",
        "    objects_list = []\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_count += 1\n",
        "        if frame_count % 100 == 0:  # Extract one frame every 100 frames\n",
        "            # Detect objects/text in the frame using YOLO\n",
        "            blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
        "            net.setInput(blob)\n",
        "            layer_names = net.getLayerNames()\n",
        "            output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "            outs = net.forward(output_layers)\n",
        "            # Extract detected objects/text and their confidence scores\n",
        "            class_ids = []\n",
        "            confidences = []\n",
        "            boxes = []\n",
        "            for out in outs:\n",
        "                for detection in out:\n",
        "                    scores = detection[5:]\n",
        "                    class_id = np.argmax(scores)\n",
        "                    confidence = scores[class_id]\n",
        "                    if confidence > 0.5:\n",
        "                        # Object detected\n",
        "                        center_x = int(detection[0] * frame.shape[1])\n",
        "                        center_y = int(detection[1] * frame.shape[0])\n",
        "                        width = int(detection[2] * frame.shape[1])\n",
        "                        height = int(detection[3] * frame.shape[0])\n",
        "                        left = int(center_x - width / 2)\n",
        "                        top = int(center_y - height / 2)\n",
        "                        if class_id !=0:\n",
        "                          class_ids.append(class_id)\n",
        "                        confidences.append(float(confidence))\n",
        "                        boxes.append([left, top, width, height])\n",
        "            # Add class_ids to list for each frame\n",
        "            class_ids_list.append(class_ids)\n",
        "            frames.append(frame)\n",
        "            objects = []\n",
        "            for class_id in class_ids_list:\n",
        "              for c_id in class_id:\n",
        "                objects.append(classes[c_id])\n",
        "            objects = list(set(objects))  # Keep only unique objects in the list\n",
        "            objects_list.append(objects)\n",
        "    cap.release()\n",
        "    return objects"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below is used create a new column named 'Objects' in the dataframe and extract objects from the last 50 videos using YOLO and the list of objects is put in the Objects column of the data frame.\n",
        "**NOTE:** **DO NOT RUN THE FUNCTION BELOW**"
      ],
      "metadata": {
        "id": "f0YT6Z-vu51c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "pduaJqSdEnVV"
      },
      "outputs": [],
      "source": [
        "url = 'https://raw.githubusercontent.com/Rohan581/Video-Recommendation/main/Youtube_Video_Dataset.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "data = data.iloc[-50:]\n",
        "\n",
        "data['Videourl'] = \"www.youtube.com\" + data['Videourl']\n",
        "\n",
        "url_list = data['Videourl'].values.tolist()\n",
        "\n",
        "data['Objects'] = None\n",
        "data['Objects'] = data['Objects'].astype(object)\n",
        "\n",
        "for url in range(50):\n",
        "    ext_objs = extract_frames_with_yolo(url_list[url])\n",
        "    print(ext_objs)\n",
        "    data['Objects'] = data['Objects'].astype(object)\n",
        "    data.at[11161 + url, 'Objects'] = ext_objs\n",
        "\n",
        "data.to_csv('Extracted Objects.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function detects objects from an image"
      ],
      "metadata": {
        "id": "J4yGzbEEyG0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_objects(image_path):\n",
        "\n",
        "    # Load image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Detect objects in the image using YOLO\n",
        "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    layer_names = net.getLayerNames()\n",
        "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "    outs = net.forward(output_layers)\n",
        "\n",
        "    frames = []\n",
        "    class_ids_list = [] # List of class_ids for each frame\n",
        "    objects_list = []\n",
        "\n",
        "    # Extract detected objects and their confidence scores\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                # Object detected\n",
        "                center_x = int(detection[0] * image.shape[1])\n",
        "                center_y = int(detection[1] * image.shape[0])\n",
        "                width = int(detection[2] * image.shape[1])\n",
        "                height = int(detection[3] * image.shape[0])\n",
        "                left = int(center_x - width / 2)\n",
        "                top = int(center_y - height / 2)\n",
        "                if class_id !=0:\n",
        "                    class_ids.append(class_id)\n",
        "                    confidences.append(float(confidence))\n",
        "                    boxes.append([left, top, width, height])\n",
        "            # Add class_ids to list for each frame\n",
        "            class_ids_list.append(class_ids)\n",
        "            objects = []\n",
        "            for class_id in class_ids_list:\n",
        "                for c_id in class_id:\n",
        "                    objects.append(classes[c_id])\n",
        "            objects = list(set(objects))  # Keep only unique objects in the list\n",
        "            objects_list.append(objects)\n",
        "    return objects"
      ],
      "metadata": {
        "id": "iXnYiHEgFxjW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function below will calculate the cosine similarity between two lists of strings"
      ],
      "metadata": {
        "id": "vLMhG8jpyQ_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def cosine_similarity_strings(str_list1, str_list2):\n",
        "    # Combine the input lists of strings into single strings\n",
        "    str1 = ' '.join(str_list1)\n",
        "    str2 = ' '.join(str_list2)\n",
        "\n",
        "    # Create a CountVectorizer object and transform the strings into a sparse matrix of token counts\n",
        "    vectorizer = CountVectorizer().fit_transform([str1, str2])\n",
        "\n",
        "    # Compute the cosine similarity between the two sparse matrices\n",
        "    cosine_sim = cosine_similarity(vectorizer[0], vectorizer[1])[0][0]\n",
        "\n",
        "    return cosine_sim"
      ],
      "metadata": {
        "id": "APi6_3rBlRX8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To save time I've already extracted objects from 50 data points and around 32 of them were valid. I've saved the extracted objects as explained above and stored them in a **csv** file in my github account. Run the below function to get videos similar to the image that you're going to upload and these videos are sorted accorind to similarity score."
      ],
      "metadata": {
        "id": "M8X7WabwwDOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/Rohan581/Video-Recommendation/main/Extracted%20Objects.csv')\n",
        "data['Objects'] = data['Objects'].apply(ast.literal_eval)\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "# Rename the file\n",
        "os.rename(filename, 'input_file.jpg')\n",
        "objects = detect_objects('input_file.jpg')\n",
        "data['Similarity'] = 0.0\n",
        "\n",
        "for ind in range(len(data['Objects'])):\n",
        "    data['Similarity'][ind] = cosine_similarity_strings(objects, data['Objects'][ind])\n",
        "\n",
        "data = data[data['Similarity']>0]\n",
        "data.sort_values(by='Similarity', ascending=False)\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "  print(f\"Title: {row[0]} , Link: {row[1]}\")"
      ],
      "metadata": {
        "id": "_etrK1nRq8fh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "13f6seOlZ1lPFlpc1pAz9KDsD1MP_6pyv",
      "authorship_tag": "ABX9TyMJCvVMU9tOJC0YspaJNKkR",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}